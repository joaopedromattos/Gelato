{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrm28/.conda/envs/gelato/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1],\n",
       " 1: [1],\n",
       " 2: [1],\n",
       " 3: [1],\n",
       " 4: [1],\n",
       " 5: [1],\n",
       " 6: [1],\n",
       " 7: [1],\n",
       " 8: [1],\n",
       " 9: [1],\n",
       " 10: [1],\n",
       " 11: [1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: [1] for key in np.unique(r)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array([[0, 1], [1, 4], [1, 5], [1, 6], [0, 2], [2, 7], [0, 3], [3, 8], [3, 9], [3, 10], [3, 11]]).transpose()\n",
    "r = np.array([l[1, :], l[0, :]])\n",
    "edge_index = torch.from_numpy(r)\n",
    "\n",
    "train_loader = pyg.loader.NeighborSampler(edge_index, sizes=[1])\n",
    "\n",
    "\n",
    "# train_loader = pyg.loader.NeighborLoader(edge_index, num_neighbors=[1], batch_size=1, input_nodes=None)\n",
    "                            \n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " tensor([1, 4, 5, 6, 4]),\n",
       " EdgeIndex(edge_index=tensor([[4],\n",
       "         [0]]), e_id=tensor([1]), size=(5, 5)))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.sample([1, 4, 5, 6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_degree(edge_index, num_nodes, out=True):\n",
    "    return pyg.utils.degree(edge_index[0 if out else 1], num_nodes)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.3333, 1.0000, 0.2500,    inf,    inf,    inf,    inf,    inf,\n",
       "           inf,    inf,    inf])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / new_degree(edge_index, len(np.unique(r)), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_bfs(A, nodes, p, k_hop):\n",
    "\n",
    "    nodes_to_be_explored = [**nodes]\n",
    "    final_neighbors = []\n",
    "    k = 0\n",
    "\n",
    "    for k in range(k_hop):\n",
    "        while nodes_to_be_explored:\n",
    "            cur_node = nodes_to_be_explored.pop()\n",
    "            neighbors = torch.nonzero(A[cur_node])\n",
    "\n",
    "            indices = torch.randperm(len(neighbors))[:10]\n",
    "\n",
    "            final_neighbors.extend(neighbors[indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrm28/.conda/envs/gelato/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ogb.linkproppred import PygLinkPropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name = \"ogbl-ppa\") \n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "graph = dataset[0] # pyg graph object containing only training edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch_geometric.datasets import Planetoid, Amazon, PPI\n",
    "from torch_geometric.utils import negative_sampling, add_self_loops, train_test_split_edges, k_hop_subgraph\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_random_seed(random_seed):\n",
    "    \"\"\"\n",
    "    Set the random seed.\n",
    "    :param random_seed: Seed to be set.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "\n",
    "def split_dataset(data, valid_ratio=0.05, test_ratio=0.1, random_seed=0):\n",
    "    \"\"\"\n",
    "    Split the edges/nonedges for biased training, full training, (full) validation and (full) testing.\n",
    "\n",
    "    :param data: PyG dataset data.\n",
    "    :param valid_ratio: ratio of validation edges.\n",
    "    :param test_ratio: ratio of test edges.\n",
    "    :param random_seed: random seed for the split.\n",
    "    :return: edge splits\n",
    "    \"\"\"\n",
    "\n",
    "    set_random_seed(random_seed)\n",
    "    n = data.num_nodes\n",
    "\n",
    "    print(data)\n",
    "    split_data = train_test_split_edges(data, valid_ratio, test_ratio)\n",
    "    split_edge = {'biased_train': {}, 'valid': {}, 'test': {}, 'train': {}}\n",
    "\n",
    "    # Biased training with negative sampling.\n",
    "    split_edge['biased_train']['edge'] = split_data.train_pos_edge_index.t()\n",
    "    edge_index, _ = add_self_loops(split_data.train_pos_edge_index)  # To avoid negative sampling of self loops.\n",
    "    split_data.train_neg_edge_index = negative_sampling(\n",
    "        edge_index, num_nodes=split_data.num_nodes,\n",
    "        num_neg_samples=split_data.train_pos_edge_index.size(1))\n",
    "    split_edge['biased_train']['edge_neg'] = split_data.train_neg_edge_index.t()\n",
    "\n",
    "    # Full training with all negative pairs in the training graph (including validation and testing positive edges).\n",
    "    split_edge['train']['edge'] = split_data.train_pos_edge_index.t()\n",
    "    train_edge_neg_mask = torch.ones((n, n), dtype=bool)\n",
    "    train_edge_neg_mask[tuple(split_edge['train']['edge'].t().tolist())] = False\n",
    "    train_edge_neg_mask = torch.triu(train_edge_neg_mask, 1)\n",
    "    split_edge['train']['edge_neg'] = torch.nonzero(train_edge_neg_mask)\n",
    "\n",
    "    # Full validation with all negative pairs in the training graph (including testing positive edges, excluding validation positive edges).\n",
    "    split_edge['valid']['edge'] = split_data.val_pos_edge_index.t()\n",
    "    valid_edge_neg_mask = train_edge_neg_mask.clone()\n",
    "    valid_edge_neg_mask[tuple(split_edge['valid']['edge'].t().tolist())] = False\n",
    "    split_edge['valid']['edge_neg'] = torch.nonzero(valid_edge_neg_mask)\n",
    "\n",
    "    # Full testing with all negative pairs in the training graph (excluding validation and testing positive edges).\n",
    "    split_edge['test']['edge'] = split_data.test_pos_edge_index.t()\n",
    "    test_edge_neg_mask = valid_edge_neg_mask.clone()\n",
    "    test_edge_neg_mask[tuple(split_edge['test']['edge'].t().tolist())] = False\n",
    "    split_edge['test']['edge_neg'] = torch.nonzero(test_edge_neg_mask)\n",
    "\n",
    "    return split_edge\n",
    "\n",
    "\n",
    "\n",
    "def compute_edges(split_edge):\n",
    "    \"\"\"\n",
    "    Compute the train, valid, and test edges based on edge split.\n",
    "\n",
    "    :param split_edge: edge split.\n",
    "    :return: train_edges_pos, train_edges_neg, valid_edges, valid_true, test_edges, test_true\n",
    "    \"\"\"\n",
    "\n",
    "    # Train edges.\n",
    "    train_edges_pos = split_edge['train']['edge']\n",
    "    train_edges_pos = train_edges_pos[train_edges_pos[:, 0] < train_edges_pos[:, 1]]  # Only include upper triangle.\n",
    "    train_edges_neg = split_edge['train']['edge_neg']\n",
    "\n",
    "    # Valid edges.\n",
    "    valid_edges = torch.vstack([split_edge['valid']['edge'], split_edge['valid']['edge_neg']])\n",
    "    valid_true = torch.cat([torch.ones(split_edge['valid']['edge'].shape[0], dtype=int), torch.zeros(split_edge['valid']['edge_neg'].shape[0], dtype=int)])\n",
    "    index = torch.randperm(valid_edges.shape[0])  # Shuffle edges for expected values of precision@k for ties.\n",
    "    valid_edges = valid_edges[index]\n",
    "    valid_true = valid_true[index]\n",
    "\n",
    "    # Test edges.\n",
    "    test_edges = torch.vstack([split_edge['test']['edge'], split_edge['test']['edge_neg']])\n",
    "    test_true = torch.cat([torch.ones(split_edge['test']['edge'].shape[0], dtype=int), torch.zeros(split_edge['test']['edge_neg'].shape[0], dtype=int)])\n",
    "    index = torch.randperm(test_edges.shape[0])\n",
    "    test_edges = test_edges[index]\n",
    "    test_true = test_true[index]\n",
    "\n",
    "    return train_edges_pos, train_edges_neg, valid_edges, valid_true, test_edges, test_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=576289, edge_index=[2, 42463862], x=[576289, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jrm28/.conda/envs/gelato/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 332109011521 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# data.edge_attr = torch.ones([data.edge_index.shape[1], 1], dtype=int)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m split_edge \u001b[39m=\u001b[39m split_dataset(data)\n\u001b[1;32m      3\u001b[0m data\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m split_edge[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39medge\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mt()\n\u001b[1;32m      4\u001b[0m data\u001b[39m.\u001b[39medge_weight \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtrain_pos_edge_attr\n",
      "Cell \u001b[0;32mIn [15], line 33\u001b[0m, in \u001b[0;36msplit_dataset\u001b[0;34m(data, valid_ratio, test_ratio, random_seed)\u001b[0m\n\u001b[1;32m     30\u001b[0m n \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnum_nodes\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(data)\n\u001b[0;32m---> 33\u001b[0m split_data \u001b[39m=\u001b[39m train_test_split_edges(data, valid_ratio, test_ratio)\n\u001b[1;32m     34\u001b[0m split_edge \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbiased_train\u001b[39m\u001b[39m'\u001b[39m: {}, \u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m: {}, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m: {}, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m: {}}\n\u001b[1;32m     36\u001b[0m \u001b[39m# Biased training with negative sampling.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/gelato/lib/python3.9/site-packages/torch_geometric/deprecation.py:13\u001b[0m, in \u001b[0;36mdeprecated.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfunc_name \u001b[39mor\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is deprecated\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m (\n\u001b[1;32m     11\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mdetails\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m details \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m warnings\u001b[39m.\u001b[39mwarn(out)\n\u001b[0;32m---> 13\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/gelato/lib/python3.9/site-packages/torch_geometric/utils/train_test_split_edges.py:80\u001b[0m, in \u001b[0;36mtrain_test_split_edges\u001b[0;34m(data, val_ratio, test_ratio)\u001b[0m\n\u001b[1;32m     77\u001b[0m     data\u001b[39m.\u001b[39mtrain_pos_edge_index \u001b[39m=\u001b[39m to_undirected(data\u001b[39m.\u001b[39mtrain_pos_edge_index)\n\u001b[1;32m     79\u001b[0m \u001b[39m# Negative edges.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m neg_adj_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mones(num_nodes, num_nodes, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49muint8)\n\u001b[1;32m     81\u001b[0m neg_adj_mask \u001b[39m=\u001b[39m neg_adj_mask\u001b[39m.\u001b[39mtriu(diagonal\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mbool)\n\u001b[1;32m     82\u001b[0m neg_adj_mask[row, col] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 332109011521 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "\n",
    "# data.edge_attr = torch.ones([data.edge_index.shape[1], 1], dtype=int)\n",
    "split_edge = split_dataset(data)\n",
    "data.edge_index = split_edge['train']['edge'].t()\n",
    "data.edge_weight = data.train_pos_edge_attr\n",
    "train_edges_pos, train_edges_neg, valid_edges, valid_true, test_edges, test_true = compute_edges(split_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21231931, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_edge['train']['edge'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('gelato')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4762024396ae022be5cc30968dc74418e5d4ce3c93b013718e4578fbe9cf2227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
